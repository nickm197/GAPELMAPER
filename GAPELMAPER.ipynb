{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "import html\n",
    "import os\n",
    "from sklearn.metrics import  mean_absolute_percentage_error\n",
    "import re\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy.optimize import curve_fit\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# –°–ø–∏—Å–æ–∫ —Ç–æ—á–µ–∫ –Ω–∞ —Å–∫–æ–ª—å–∫–æ –Ω–∞–¥–æ —Å–¥–≤–∏–Ω—É—Ç—å –≤–µ–∫—Ç–æ—Ä–∞ –º–µ–∂–¥—É —Å–æ–±–æ–π —á—Ç–æ–±—ã –ø–æ—Å—á–∏—Ç–∞—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ \n",
    "POWER = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200, 300, 400, 500, 600, 700, 800, 900,\n",
    "         1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000, 20000, 30000, 40000]"
   ],
   "id": "9593f9bc7cf0d272"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "–§—É–Ω–∫—Ü–∏–∏ –¥–ª—è –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞",
   "id": "dc1f82fa04f44c3e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Convert all named and numeric character references (e.g. &gt;, &#62;,\n",
    "    &x3e;) in the string s to the corresponding unicode characters.\n",
    "    This function uses the rules defined by the HTML 5 standard\n",
    "    for both valid and invalid character references, and the list of\n",
    "    HTML 5 named character references defined in html.entities.html5.\n",
    "    Args:\n",
    "        text: Book text.\n",
    "\n",
    "    Returns:\n",
    "        Book text in lowercase letters.\n",
    "    \"\"\"\n",
    "    text = html.unescape(text)  # &amp;#x200B; => &#x200B;\n",
    "    text = html.unescape(text)  # &amp;#x200B; =>\n",
    "    return text.lower()\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    Return the string obtained by replacing the leftmost\n",
    "    non-overlapping occurrences of the pattern in string by the\n",
    "    replacement repl.  repl can be either a string or a callable;\n",
    "    if a string, backslash escapes in it are processed.  If it is\n",
    "    a callable, it's passed the Match object and must return\n",
    "    a replacement string to be used.\n",
    "    Args:\n",
    "        text: Book text.\n",
    "\n",
    "    Returns:\n",
    "        List of words.\n",
    "    \"\"\"\n",
    "    opt = re.sub(r'[^\\w\\s]', '', text)\n",
    "    words = opt.split()\n",
    "    return words"
   ],
   "id": "8cbde27887e22ceb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "–§—É–Ω–∫—Ü–∏—è get_embeddings –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç emb —Å–ª–æ–≤ –∫–æ—Ç–æ—Ä—ã–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –≤ —Å–µ–±–µ glove\n",
    "\n",
    "–ù–∞ –≤—ã—Ö–æ–¥–µ –ø–æ–ª—É—á–∞–µ—Ç—Å—è —Å–ª–æ–≤–∞—Ä—å –≤–∏–¥–∞ '—Å–ª–æ–≤–æ': emb\n",
    "\n",
    "–§—É–Ω–∫—Ü–∏—è get_tokens –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ç–æ–∫–µ–Ω–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–∞"
   ],
   "id": "2a6e527e655f420a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_embeddings(path_glove: str) -> Dict[str, np.ndarray]:\n",
    "    \"\"\"\n",
    "    The function returns a dictionary, the key is a word, the value is a vector embedding\n",
    "    Args:\n",
    "        path_glove: Path to the glove file.\n",
    "\n",
    "    Returns:\n",
    "        The function returns a dictionary Dict[str, np.ndarray], the key is a word, the value is a vector embedding\n",
    "    \"\"\"\n",
    "    embeddings = {}\n",
    "    with open(path_glove, 'r', encoding='utf-8') as file:\n",
    "\n",
    "        for line in tqdm(file):\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            embedding = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings[word] = embedding\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def get_tokens(path_text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    The function returns a list of tokens from text.\n",
    "    Args:\n",
    "        path_text: Path to the text file.\n",
    "\n",
    "    Returns:\n",
    "        List of tokens from text.\n",
    "    \"\"\"\n",
    "    tokens = []\n",
    "    with open(path_text, encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            tokens += tokenize(preprocess_text(line))\n",
    "    return tokens"
   ],
   "id": "42d81522c72e47b9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "–§—É–Ω–∫—Ü–∏—è get_tokens_with_embeddings –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å emb, —Ç–æ–ª—å–∫–æ —Å–æ —Å–ª–æ–≤–∞–º–∏ –∫–æ—Ç–æ—Ä—ã–µ –µ—Å—Ç—å –≤ glove\n",
    "\n",
    "–§—É–Ω–∫—Ü–∏—è get_normalized_embeddings –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä–∞. \n",
    "\n",
    "–§—É–Ω–∫—Ü–∏—è get_norms_embeddings –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–æ—Ä–º—ã –≤–µ–∫—Ç–æ—Ä–æ–≤"
   ],
   "id": "c2fd0dc79a00c99c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_tokens_with_embeddings(embeddings: np.ndarray, tokens: List, verbose: bool = False) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    The function finds embeddings of words that are in the book.\n",
    "    Args:\n",
    "        embeddings: Embeddings.\n",
    "        tokens: Tokens.\n",
    "        verbose: Console output of a word that is not in the dictionary glove\n",
    "        (False do not output to console, True output to console).\n",
    "\n",
    "    Returns:\n",
    "        Embeddings of words that are in the book.\n",
    "    \"\"\"\n",
    "    tokens_with_embeddings = []\n",
    "    for token in tokens:\n",
    "        try:\n",
    "            tokens_with_embeddings.append(embeddings[token])\n",
    "        except KeyError:\n",
    "            if verbose:\n",
    "                print('Not found', token)\n",
    "\n",
    "    return np.asarray(tokens_with_embeddings, dtype='float32')\n",
    "\n",
    "\n",
    "def get_normalized_embeddings(embeddings: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    The function finds the weighted average values of embeddings.\n",
    "    Args:\n",
    "        embeddings: Embeddings.\n",
    "\n",
    "    Returns:\n",
    "        The function returns array weighted average values of embeddings.\n",
    "    \"\"\"\n",
    "    quantity, dim = embeddings.shape\n",
    "    avg = np.zeros(dim)\n",
    "    for i in range(quantity):\n",
    "        avg += embeddings[i]\n",
    "    avg = avg / quantity\n",
    "\n",
    "    for i in range(quantity):\n",
    "        embeddings[i] -= avg\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def get_norms_embeddings(embeddings: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    The function finds the norm of vectors.\n",
    "    Args:\n",
    "        embeddings: Embeddings.\n",
    "\n",
    "    Returns:\n",
    "        Norm of word vectors.\n",
    "    \"\"\"\n",
    "    quantity = len(embeddings)\n",
    "    norms = np.zeros(quantity)\n",
    "\n",
    "    for i in range(quantity):\n",
    "        norms[i] = np.linalg.norm(embeddings[i])\n",
    "    return norms"
   ],
   "id": "3a41ccc3513dd15b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "–§—É–Ω–∫—Ü–∏—è get_autocorrelation —Å—á–∏—Ç–∞–µ—Ç –∞–≤—Ç–æ–∫–æ—Ä—Ä–µ–ª—è—Ü–∏—é",
   "id": "e60cdad90e06e5eb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_autocorrelation(embeddings: np.ndarray, norms: np.ndarray, number_embeddings: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    The function finds the autocorrelation values of word vectors\n",
    "    Args:\n",
    "        embeddings: Embeddings.\n",
    "        norms: Norm of word vectors.\n",
    "        number_embeddings: Number of Embeddings.\n",
    "\n",
    "    Returns:\n",
    "        Array of correlation values\n",
    "    \"\"\"\n",
    "    autocorr = np.zeros(len(POWER))\n",
    "    for k in tqdm(range(len(POWER))):\n",
    "        sumcorr = 0.\n",
    "        j = POWER[k]\n",
    "        for i in range(number_embeddings - j):\n",
    "            corr = np.dot(embeddings[i], embeddings[i + j]) / norms[i] / norms[i + j]\n",
    "            sumcorr += corr\n",
    "        autocorr[k] = sumcorr / (number_embeddings - j)\n",
    "    return autocorr"
   ],
   "id": "dcf93b338f29aafc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "GAPELMAPER —Å—á–∏—Ç–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏",
   "id": "78df57b35d74bb06"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class GAPELMAPER:\n",
    "    \"\"\"\n",
    "    Using this class you can find the metric GAPELMAPER.\n",
    "\n",
    "    Args:\n",
    "        self.values_x:\n",
    "        self.values_y: Array of correlation values\n",
    "        self.negative_index: Index of the first non-negative value after the last index of the negative value.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, values_x: np.array, values_y: np.array):\n",
    "        self.negative_index = 0\n",
    "        self.values_x = values_x\n",
    "        self.values_y = values_y\n",
    "        self.y_fitpow = None\n",
    "        self.y_fitexp = None\n",
    "        self.y_fitlog = None\n",
    "        self.__get_negative_index()\n",
    "\n",
    "    def __get_negative_index(self):\n",
    "        \"\"\"The method finds the extreme (maximum) index of a non-negative value\"\"\"\n",
    "        neg = np.where(self.values_y <= 0)[0]\n",
    "        if neg.size > 0:\n",
    "            self.negative_index = np.max(neg) + 1\n",
    "\n",
    "    @staticmethod\n",
    "    def __mapping(x: np.array, a: float, b: float) -> np.array:\n",
    "        \"\"\"\n",
    "        The method approximates the direct correlation value.\n",
    "\n",
    "        Args:\n",
    "            x: the coordinates of any point on the line\n",
    "            a: is the slope of the line.\n",
    "            b: is the y-intercept (where the line crosses the y-axis).\n",
    "\n",
    "        Return:\n",
    "            Returns an array of numbers.\n",
    "        \"\"\"\n",
    "        return a * x + b\n",
    "\n",
    "    def get_power_mape(self):\n",
    "        \"\"\"\n",
    "            The method finds the average absolute percentage error for a power law.\n",
    "        Returns:\n",
    "            The method returns the average absolute percentage error for a power law.\n",
    "        \"\"\"\n",
    "        values_x = np.log10(self.values_x[self.negative_index:])\n",
    "        values_y = np.log10(self.values_y[self.negative_index:])\n",
    "\n",
    "        argspow, _ = curve_fit(self.__mapping, values_x, values_y)\n",
    "        self.y_fitpow = self.__mapping(values_x, argspow[0], argspow[1])\n",
    "        return mean_absolute_percentage_error(self.values_y[self.negative_index:], 10 ** self.y_fitpow)\n",
    "\n",
    "    def get_log_mape(self):\n",
    "        \"\"\"\n",
    "            The method finds the average absolute percentage error for a logarithmic law.\n",
    "        Returns:\n",
    "            The method returns the average absolute percentage error for a logarithmic law.\n",
    "        \"\"\"\n",
    "        values_x = np.log10(self.values_x[self.negative_index:])\n",
    "        values_y = self.values_y[self.negative_index:]\n",
    "\n",
    "        argslog, _ = curve_fit(self.__mapping, values_x, values_y)\n",
    "        self.y_fitlog = self.__mapping(values_x, argslog[0], argslog[1])\n",
    "        return mean_absolute_percentage_error(values_y, self.y_fitlog)\n",
    "\n",
    "    def get_exp_mape(self):\n",
    "        \"\"\"\n",
    "            The method finds the average absolute percentage error for an exponential law.\n",
    "        Returns:\n",
    "            The method returns the average absolute percentage error for an exponential law.\n",
    "        \"\"\"\n",
    "        values_x = self.values_x[self.negative_index:]\n",
    "        values_y = np.log10(self.values_y[self.negative_index:])\n",
    "\n",
    "        argsexp, _ = curve_fit(self.__mapping, values_x, values_y)\n",
    "        self.y_fitexp = self.__mapping(values_x, argsexp[0], argsexp[1])\n",
    "        return mean_absolute_percentage_error(self.values_y[self.negative_index:], 10 ** self.y_fitexp)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_gapelmaper(power_mape, exp_mape):\n",
    "        \"\"\"\n",
    "        Find GAPELMAPER.\n",
    "        Args:\n",
    "            power_mape: Average absolute percentage error for a power law.\n",
    "            exp_mape: Average absolute percentage error for an exponential law\n",
    "\n",
    "        Returns:\n",
    "            Metric GAPELMAPER.\n",
    "        \"\"\"\n",
    "        return power_mape / exp_mape"
   ],
   "id": "d5cb699e740f75f2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# –ó–∞–º–µ–Ω–∏—Ç—å –ø—É—Ç–∏ –Ω–∞ —Å–≤–æ–∏!!!\n",
    "path_glove = 'Glove/multilingual_embeddings.en'\n",
    "path_text = 'LongText/Don Quijote de la Mancha EN.txt'  \n",
    "    \n",
    "_, filename = os.path.split(path_text)\n",
    "\n",
    "embeddings = get_embeddings(path_glove)\n",
    "print('Found %s word vectors.' % len(embeddings))\n",
    "tokens = get_tokens(path_text)\n",
    "print('All tokens in', filename, len(tokens))\n",
    "tokens_with_embeddings = get_tokens_with_embeddings(embeddings, tokens, verbose=False)\n",
    "print(\"tokens with embeddings\", len(tokens_with_embeddings))\n",
    "\n",
    "normalized_embeddings = get_normalized_embeddings(tokens_with_embeddings)\n",
    "print('Embeddings normalized', normalized_embeddings.shape, normalized_embeddings.mean())\n",
    "\n",
    "quantity_embeddings = len(normalized_embeddings)\n",
    "norms = get_norms_embeddings(normalized_embeddings)\n",
    "autocorr = get_autocorrelation(normalized_embeddings, norms, quantity_embeddings)\n",
    "print(filename)\n",
    "\n",
    "metric = GAPELMAPER(np.array(POWER), autocorr)\n",
    "\n",
    "print('Power decay')\n",
    "MAPE_POWER = metric.get_power_mape()\n",
    "print('MAPE =', MAPE_POWER)\n",
    "print()\n",
    "print('Log decay')\n",
    "MAPE_LOG = metric.get_log_mape()\n",
    "print('MAPE =', MAPE_LOG)\n",
    "print()\n",
    "print('Exp decay')\n",
    "MAPE_EXP = metric.get_exp_mape()\n",
    "print('MAPE =', MAPE_EXP)\n",
    "print()\n",
    "print('GAPELMAPER')\n",
    "print(metric.get_gapelmaper(MAPE_POWER, MAPE_EXP))"
   ],
   "id": "1b4017158eb0aac3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class CustomPlot:\n",
    "\n",
    "    def __init__(self, autocorr):\n",
    "        self.autocorr = autocorr\n",
    "\n",
    "    def get_autocorr_plot(self):\n",
    "        fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(15, 15))\n",
    "\n",
    "        # add data to plots\n",
    "        ax[0, 0].plot(POWER, self.autocorr, label='corr')\n",
    "        ax[0, 0].grid(True)\n",
    "        ax[0, 0].set_xlabel('Log distance', size='large')\n",
    "        ax[0, 0].set_ylabel('Log Correlation', size='large')\n",
    "        ax[0, 0].set_yscale('log')\n",
    "        ax[0, 0].set_xscale('log')\n",
    "\n",
    "        ax[0, 1].plot(POWER, self.autocorr, label='corr')\n",
    "        ax[0, 1].grid(True)\n",
    "        ax[0, 1].set_xlabel('Distance', size='large')\n",
    "        ax[0, 1].set_ylabel('Log Correlation', size='large')\n",
    "        ax[0, 1].set_yscale('log')\n",
    "\n",
    "        ax[1, 0].plot(POWER, self.autocorr, label='corr')\n",
    "        ax[1, 0].grid(True)\n",
    "        ax[1, 0].set_xlabel('Log distance', size='large')\n",
    "        ax[1, 0].set_ylabel('Correlation', size='large')\n",
    "        ax[1, 0].set_xscale('log')\n",
    "\n",
    "        ax[1, 1].plot(POWER, self.autocorr, label='corr')\n",
    "        ax[1, 1].grid(True)\n",
    "        ax[1, 1].set_xlabel('Distance', size='large')\n",
    "        ax[1, 1].set_ylabel('Correlation', size='large')\n",
    "        plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def plotting_the_graph_correlation(x: np.array, y_original: np.array, y_predict: np.array, logx: str, logy: str):\n",
    "        \"\"\"\n",
    "        The function displays a graph of calculated correlation values,\n",
    "        and a direct approximation of the correlation values.\n",
    "\n",
    "        Args:\n",
    "            x: Array of shifts of the matrix of attention vectors\n",
    "            y_original: Array of correlation values\n",
    "            y_predict: An array of values approximating the correlation\n",
    "            logx: \n",
    "            logy:\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.plot(x, y_original, 'bo', label=\"y - original\")\n",
    "        plt.plot(x, y_predict, label=\"y = a * x + b\")\n",
    "        plt.xlabel(logx + r'$\\tau$', fontsize=24, fontweight=\"bold\")  # ('ùúè')\n",
    "        plt.ylabel(logy + r' C($\\tau$)', fontsize=24, fontweight=\"bold\")\n",
    "        plt.legend(loc='best', fancybox=True, shadow=True)\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    @staticmethod\n",
    "    def get_discrepancy_plot(values_x: np.ndarray,\n",
    "                             values_y: np.ndarray,\n",
    "                             y_fitpow: np.ndarray,\n",
    "                             y_fitlog: np.ndarray,\n",
    "                             y_fitexp: np.ndarray,\n",
    "                             negative_index: int = 0):\n",
    "        discrep_power = values_y[negative_index:] - 10 ** y_fitpow\n",
    "        discrep_log = values_y[negative_index:] - y_fitlog\n",
    "        discrep_exp = values_y[negative_index:] - 10 ** y_fitexp\n",
    "\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(14, 4))\n",
    "        ax[0].plot(values_x[negative_index:], discrep_power, 'bo', label='discrepancy of power fit')\n",
    "        ax[0].grid(True)\n",
    "        ax[0].set_xlabel(r'$\\tau$', fontsize=24, fontweight=\"bold\")\n",
    "        ax[0].set_ylabel(r'discrepancy', fontsize=12, fontweight=\"bold\")\n",
    "        ax[0].set_xscale('log')\n",
    "\n",
    "        ax[1].plot(values_x[negative_index:], discrep_exp, 'bo', label='discrepancy of exp fit')\n",
    "        ax[1].grid(True)\n",
    "        ax[1].set_xlabel(r'$\\tau$', fontsize=24, fontweight=\"bold\")\n",
    "        ax[1].set_ylabel(r'discrepancy', fontsize=12, fontweight=\"bold\")\n",
    "        ax[1].set_xscale('log')\n",
    "\n",
    "        ax[2].plot(values_x[negative_index:], discrep_log, 'bo', label='discrepancy of log fit')\n",
    "        ax[2].grid(True)\n",
    "        ax[2].set_xlabel(r'$\\tau$', fontsize=24, fontweight=\"bold\")\n",
    "        ax[2].set_ylabel(r'discrepancy', fontsize=12, fontweight=\"bold\")\n",
    "        ax[2].set_xscale('log')\n",
    "        plt.show()"
   ],
   "id": "57ac2e6b99d6853a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plot_ = CustomPlot(autocorr)\n",
    "plot_.get_autocorr_plot()"
   ],
   "id": "36bdaec7f3da9b39"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "values_x = np.log10(np.array(POWER)[metric.negative_index:])\n",
    "values_y = np.log10(autocorr[metric.negative_index:])\n",
    "\n",
    "plot_.plotting_the_graph_correlation(values_x, values_y, metric.y_fitpow, 'Log',  'Log')"
   ],
   "id": "72294b5518af3dab"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "values_x = np.log10(np.array(POWER)[metric.negative_index:])\n",
    "values_y = autocorr[metric.negative_index:]\n",
    "\n",
    "plot_.plotting_the_graph_correlation(values_x, values_y, metric.y_fitlog, 'Log',  '')"
   ],
   "id": "197aae47bd3947cc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "values_x = np.array(POWER)[metric.negative_index:]\n",
    "values_y = np.log10(autocorr[metric.negative_index:])\n",
    "\n",
    "plot_.plotting_the_graph_correlation(values_x, values_y, metric.y_fitexp, '',  'Log')"
   ],
   "id": "6941812e6ca62b60"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "values_x = np.array(POWER)\n",
    "values_y = autocorr\n",
    "\n",
    "plot_.get_discrepancy_plot(values_x, values_y, metric.y_fitpow, metric.y_fitlog, metric.y_fitexp, metric.negative_index)"
   ],
   "id": "17db6964d97fe9ee"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
